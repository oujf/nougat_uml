class RsdCpuReferenceImpl
!!!46889527.cpp!!!	~RsdCpuReferenceImpl()
    mExit = true;
    mWorkers.mLaunchData = nullptr;
    mWorkers.mLaunchCallback = nullptr;
    mWorkers.mRunningCount = mWorkers.mCount;
    __sync_synchronize();
    for (uint32_t ct = 0; ct < mWorkers.mCount; ct++) {
        mWorkers.mLaunchSignals[ct].set();
    }
    void *res;
    for (uint32_t ct = 0; ct < mWorkers.mCount; ct++) {
        pthread_join(mWorkers.mThreadId[ct], &res);
    }
    rsAssert(__sync_fetch_and_or(&mWorkers.mRunningCount, 0) == 0);
    free(mWorkers.mThreadId);
    free(mWorkers.mNativeThreadId);
    delete[] mWorkers.mLaunchSignals;

    // Global structure cleanup.
    lockMutex();
    --gThreadTLSKeyCount;
    if (!gThreadTLSKeyCount) {
        pthread_key_delete(gThreadTLSKey);
    }
    unlockMutex();

!!!46889655.cpp!!!	RsdCpuReferenceImpl(inout rsc : Context)
    mRSC = rsc;

    version_major = 0;
    version_minor = 0;
    mInKernel = false;
    memset(&mWorkers, 0, sizeof(mWorkers));
    memset(&mTlsStruct, 0, sizeof(mTlsStruct));
    mExit = false;
    mSelectRTCallback = nullptr;
    mEmbedGlobalInfo = true;
    mEmbedGlobalInfoSkipConstant = true;
!!!46889783.cpp!!!	lockMutex() : void
    pthread_mutex_lock(&gInitMutex);
!!!46889911.cpp!!!	unlockMutex() : void
    pthread_mutex_unlock(&gInitMutex);
!!!46890039.cpp!!!	init(in version_major : uint32_t, in version_minor : uint32_t, in lfn : sym_lookup_t, in slfn : script_lookup_t) : bool
    mSymLookupFn = lfn;
    mScriptLookupFn = slfn;

    lockMutex();
    if (!gThreadTLSKeyCount) {
        int status = pthread_key_create(&gThreadTLSKey, nullptr);
        if (status) {
            ALOGE("Failed to init thread tls key.");
            unlockMutex();
            return false;
        }
    }
    gThreadTLSKeyCount++;
    unlockMutex();

    mTlsStruct.mContext = mRSC;
    mTlsStruct.mScript = nullptr;
    int status = pthread_setspecific(gThreadTLSKey, &mTlsStruct);
    if (status) {
        ALOGE("pthread_setspecific %i", status);
    }

    mPageSize = sysconf(_SC_PAGE_SIZE);
    // ALOGV("page size = %ld", mPageSize);

    GetCpuInfo();

    int cpu = sysconf(_SC_NPROCESSORS_CONF);
    if(mRSC->props.mDebugMaxThreads) {
        cpu = mRSC->props.mDebugMaxThreads;
    }
    if (cpu < 2) {
        mWorkers.mCount = 0;
        return true;
    }

    // Subtract one from the cpu count because we also use the command thread as a worker.
    mWorkers.mCount = (uint32_t)(cpu - 1);

    if (mRSC->props.mLogScripts) {
      ALOGV("%p Launching thread(s), CPUs %i", mRSC, mWorkers.mCount + 1);
    }

    mWorkers.mThreadId = (pthread_t *) calloc(mWorkers.mCount, sizeof(pthread_t));
    mWorkers.mNativeThreadId = (pid_t *) calloc(mWorkers.mCount, sizeof(pid_t));
    mWorkers.mLaunchSignals = new Signal[mWorkers.mCount];
    mWorkers.mLaunchCallback = nullptr;

    mWorkers.mCompleteSignal.init();

    mWorkers.mRunningCount = mWorkers.mCount;
    mWorkers.mLaunchCount = 0;
    __sync_synchronize();

    pthread_attr_t threadAttr;
    status = pthread_attr_init(&threadAttr);
    if (status) {
        ALOGE("Failed to init thread attribute.");
        return false;
    }

    for (uint32_t ct=0; ct < mWorkers.mCount; ct++) {
        status = pthread_create(&mWorkers.mThreadId[ct], &threadAttr, helperThreadProc, this);
        if (status) {
            mWorkers.mCount = ct;
            ALOGE("Created fewer than expected number of RS threads.");
            break;
        }
    }
    while (__sync_fetch_and_or(&mWorkers.mRunningCount, 0) != 0) {
        usleep(100);
    }

    pthread_attr_destroy(&threadAttr);
    return true;
!!!46890167.cpp!!!	setPriority(in priority : int32_t) : void
    for (uint32_t ct=0; ct < mWorkers.mCount; ct++) {
        setpriority(PRIO_PROCESS, mWorkers.mNativeThreadId[ct], priority);
    }
!!!46890295.cpp!!!	launchThreads(in cbk : WorkerCallback_t, inout data : void) : void
    mWorkers.mLaunchData = data;
    mWorkers.mLaunchCallback = cbk;

    // fast path for very small launches
    MTLaunchStructCommon *mtls = (MTLaunchStructCommon *)data;
    if (mtls && mtls->dimPtr->y <= 1 && mtls->end.x <= mtls->start.x + mtls->mSliceSize) {
        if (mWorkers.mLaunchCallback) {
            mWorkers.mLaunchCallback(mWorkers.mLaunchData, 0);
        }
        return;
    }

    mWorkers.mRunningCount = mWorkers.mCount;
    __sync_synchronize();

    for (uint32_t ct = 0; ct < mWorkers.mCount; ct++) {
        mWorkers.mLaunchSignals[ct].set();
    }

    // We use the calling thread as one of the workers so we can start without
    // the delay of the thread wakeup.
    if (mWorkers.mLaunchCallback) {
        mWorkers.mLaunchCallback(mWorkers.mLaunchData, 0);
    }

    while (__sync_fetch_and_or(&mWorkers.mRunningCount, 0) != 0) {
        mWorkers.mCompleteSignal.wait();
    }
!!!46890423.cpp!!!	helperThreadProc(inout vrsc : void) : void
    RsdCpuReferenceImpl *dc = (RsdCpuReferenceImpl *)vrsc;

    uint32_t idx = __sync_fetch_and_add(&dc->mWorkers.mLaunchCount, 1);

    //ALOGV("RS helperThread starting %p idx=%i", dc, idx);

    dc->mWorkers.mLaunchSignals[idx].init();
    dc->mWorkers.mNativeThreadId[idx] = gettid();

    memset(&dc->mTlsStruct, 0, sizeof(dc->mTlsStruct));
    int status = pthread_setspecific(gThreadTLSKey, &dc->mTlsStruct);
    if (status) {
        ALOGE("pthread_setspecific %i", status);
    }

#if 0
    typedef struct {uint64_t bits[1024 / 64]; } cpu_set_t;
    cpu_set_t cpuset;
    memset(&cpuset, 0, sizeof(cpuset));
    cpuset.bits[idx / 64] |= 1ULL << (idx % 64);
    int ret = syscall(241, rsc->mWorkers.mNativeThreadId[idx],
              sizeof(cpuset), &cpuset);
    ALOGE("SETAFFINITY ret = %i %s", ret, EGLUtils::strerror(ret));
#endif

    while (!dc->mExit) {
        dc->mWorkers.mLaunchSignals[idx].wait();
        if (dc->mWorkers.mLaunchCallback) {
           // idx +1 is used because the calling thread is always worker 0.
           dc->mWorkers.mLaunchCallback(dc->mWorkers.mLaunchData, idx+1);
        }
        __sync_fetch_and_sub(&dc->mWorkers.mRunningCount, 1);
        dc->mWorkers.mCompleteSignal.set();
    }

    //ALOGV("RS helperThread exited %p idx=%i", dc, idx);
    return nullptr;
!!!46890551.cpp!!!	setTLS(inout sc : RsdCpuScriptImpl) : RsdCpuScriptImpl
    //ALOGE("setTls %p", sc);
    ScriptTLSStruct * tls = (ScriptTLSStruct *)pthread_getspecific(gThreadTLSKey);
    rsAssert(tls);
    RsdCpuScriptImpl *old = tls->mImpl;
    tls->mImpl = sc;
    tls->mContext = mRSC;
    if (sc) {
        tls->mScript = sc->getScript();
    } else {
        tls->mScript = nullptr;
    }
    return old;
!!!46890935.cpp!!!	launchForEach(in ains : Allocation, in inLen : uint32_t, inout aout : Allocation, in sc : RsScriptCall, inout mtls : MTLaunchStructForEach) : void

    //android::StopWatch kernel_time("kernel time");

    bool outerDims = (mtls->start.z != mtls->end.z) ||
                     (mtls->start.face != mtls->end.face) ||
                     (mtls->start.lod != mtls->end.lod) ||
                     (mtls->start.array[0] != mtls->end.array[0]) ||
                     (mtls->start.array[1] != mtls->end.array[1]) ||
                     (mtls->start.array[2] != mtls->end.array[2]) ||
                     (mtls->start.array[3] != mtls->end.array[3]);

    if ((mWorkers.mCount >= 1) && mtls->isThreadable && !mInKernel) {
        const size_t targetByteChunk = 16 * 1024;
        mInKernel = true;  // NOTE: The guard immediately above ensures this was !mInKernel

        if (outerDims) {
            // No fancy logic for chunk size
            mtls->mSliceSize = 1;
            launchThreads(walk_general_foreach, mtls);
        } else if (mtls->fep.dim.y > 1) {
            uint32_t s1 = mtls->fep.dim.y / ((mWorkers.mCount + 1) * 4);
            uint32_t s2 = 0;

            // This chooses our slice size to rate limit atomic ops to
            // one per 16k bytes of reads/writes.
            if ((mtls->aout[0] != nullptr) && mtls->aout[0]->mHal.drvState.lod[0].stride) {
                s2 = targetByteChunk / mtls->aout[0]->mHal.drvState.lod[0].stride;
            } else if (mtls->ains[0]) {
                s2 = targetByteChunk / mtls->ains[0]->mHal.drvState.lod[0].stride;
            } else {
                // Launch option only case
                // Use s1 based only on the dimensions
                s2 = s1;
            }
            mtls->mSliceSize = rsMin(s1, s2);

            if(mtls->mSliceSize < 1) {
                mtls->mSliceSize = 1;
            }

            launchThreads(walk_2d_foreach, mtls);
        } else {
            uint32_t s1 = mtls->fep.dim.x / ((mWorkers.mCount + 1) * 4);
            uint32_t s2 = 0;

            // This chooses our slice size to rate limit atomic ops to
            // one per 16k bytes of reads/writes.
            if ((mtls->aout[0] != nullptr) && mtls->aout[0]->getType()->getElementSizeBytes()) {
                s2 = targetByteChunk / mtls->aout[0]->getType()->getElementSizeBytes();
            } else if (mtls->ains[0]) {
                s2 = targetByteChunk / mtls->ains[0]->getType()->getElementSizeBytes();
            } else {
                // Launch option only case
                // Use s1 based only on the dimensions
                s2 = s1;
            }
            mtls->mSliceSize = rsMin(s1, s2);

            if (mtls->mSliceSize < 1) {
                mtls->mSliceSize = 1;
            }

            launchThreads(walk_1d_foreach, mtls);
        }
        mInKernel = false;

    } else {
        ForEachFunc_t fn = mtls->kernel;
        uint32_t slice = 0;


        while(SelectOuterSlice(mtls, &mtls->fep, slice++)) {
            for (mtls->fep.current.y = mtls->start.y;
                 mtls->fep.current.y < mtls->end.y;
                 mtls->fep.current.y++) {

                FepPtrSetup(mtls, &mtls->fep, mtls->start.x,
                            mtls->fep.current.y, mtls->fep.current.z, mtls->fep.current.lod,
                            (RsAllocationCubemapFace) mtls->fep.current.face,
                            mtls->fep.current.array[0], mtls->fep.current.array[1],
                            mtls->fep.current.array[2], mtls->fep.current.array[3]);

                fn(&mtls->fep, mtls->start.x, mtls->end.x, mtls->fep.outStride[0]);
            }
        }
    }
!!!46891063.cpp!!!	launchReduce(in ains : Allocation, in inLen : uint32_t, inout aout : Allocation, inout mtls : MTLaunchStructReduce) : void
  mtls->logReduce = mRSC->props.mLogReduce;
  if ((mWorkers.mCount >= 1) && mtls->isThreadable && !mInKernel) {
    launchReduceParallel(ains, inLen, aout, mtls);
  } else {
    launchReduceSerial(ains, inLen, aout, mtls);
  }
!!!46891191.cpp!!!	createScript(in s : ScriptC, in resName : char, in cacheDir : char, in bitcode : uint8_t, in bitcodeSize : size_t, in flags : uint32_t) : CpuScript

    RsdCpuScriptImpl *i = new RsdCpuScriptImpl(this, s);
    if (!i->init(resName, cacheDir, bitcode, bitcodeSize, flags
        , getBccPluginName()
        )) {
        delete i;
        return nullptr;
    }
    return i;
!!!46891319.cpp!!!	createIntrinsic(in s : Script, in iid : RsScriptIntrinsicID, inout e : Element) : CpuScript

    RsdCpuScriptImpl *i = nullptr;
    switch (iid) {
    case RS_SCRIPT_INTRINSIC_ID_3DLUT:
        i = rsdIntrinsic_3DLUT(this, s, e);
        break;
    case RS_SCRIPT_INTRINSIC_ID_CONVOLVE_3x3:
        i = rsdIntrinsic_Convolve3x3(this, s, e);
        break;
    case RS_SCRIPT_INTRINSIC_ID_COLOR_MATRIX:
        i = rsdIntrinsic_ColorMatrix(this, s, e);
        break;
    case RS_SCRIPT_INTRINSIC_ID_LUT:
        i = rsdIntrinsic_LUT(this, s, e);
        break;
    case RS_SCRIPT_INTRINSIC_ID_CONVOLVE_5x5:
        i = rsdIntrinsic_Convolve5x5(this, s, e);
        break;
    case RS_SCRIPT_INTRINSIC_ID_BLUR:
        i = rsdIntrinsic_Blur(this, s, e);
        break;
    case RS_SCRIPT_INTRINSIC_ID_YUV_TO_RGB:
        i = rsdIntrinsic_YuvToRGB(this, s, e);
        break;
    case RS_SCRIPT_INTRINSIC_ID_BLEND:
        i = rsdIntrinsic_Blend(this, s, e);
        break;
    case RS_SCRIPT_INTRINSIC_ID_HISTOGRAM:
        i = rsdIntrinsic_Histogram(this, s, e);
        break;
    case RS_SCRIPT_INTRINSIC_ID_RESIZE:
        i = rsdIntrinsic_Resize(this, s, e);
        break;
    case RS_SCRIPT_INTRINSIC_ID_BLAS:
        i = rsdIntrinsic_BLAS(this, s, e);
        break;

    default:
        rsAssert(0);
    }

    return i;
!!!46891447.cpp!!!	createScriptGroup(in sg : ScriptGroupBase) : void
  switch (sg->getApiVersion()) {
    case ScriptGroupBase::SG_V1: {
      CpuScriptGroupImpl *sgi = new CpuScriptGroupImpl(this, sg);
      if (!sgi->init()) {
        delete sgi;
        return nullptr;
      }
      return sgi;
    }
    case ScriptGroupBase::SG_V2: {
      return new CpuScriptGroup2Impl(this, sg);
    }
  }
  return nullptr;
!!!46891575.cpp!!!	symLookup(in name : char) : RsdCpuReference::CpuSymbol
    return mSymLookupFn(mRSC, name);
!!!46892983.cpp!!!	launchReduceSerial(in ains : Allocation, in inLen : uint32_t, inout aout : Allocation, inout mtls : MTLaunchStructReduce) : void
  REDUCE_ALOGV(mtls, 1, "launchReduceSerial(%p): %u x %u x %u", mtls->accumFunc,
               mtls->redp.dim.x, mtls->redp.dim.y, mtls->redp.dim.z);

  // In the presence of outconverter, we allocate temporary memory for
  // the accumulator.
  //
  // In the absence of outconverter, we use the output allocation as the
  // accumulator.
  uint8_t *const accumPtr = (mtls->outFunc
                             ? static_cast<uint8_t *>(malloc(mtls->accumSize))
                             : mtls->redp.outPtr[0]);

  // initialize
  if (mtls->initFunc) {
    mtls->initFunc(accumPtr);
  } else {
    memset(accumPtr, 0, mtls->accumSize);
  }

  // accumulate
  const ReduceAccumulatorFunc_t fn = mtls->accumFunc;
  uint32_t slice = 0;
  while (SelectOuterSlice(mtls, &mtls->redp, slice++)) {
    for (mtls->redp.current.y = mtls->start.y;
         mtls->redp.current.y < mtls->end.y;
         mtls->redp.current.y++) {
      RedpPtrSetup(mtls, &mtls->redp, mtls->start.x, mtls->redp.current.y, mtls->redp.current.z);
      fn(&mtls->redp, mtls->start.x, mtls->end.x, accumPtr);
    }
  }

  // outconvert
  if (mtls->outFunc) {
    mtls->outFunc(mtls->redp.outPtr[0], accumPtr);
    free(accumPtr);
  }
!!!46893111.cpp!!!	launchReduceParallel(in ains : Allocation, in inLen : uint32_t, inout aout : Allocation, inout mtls : MTLaunchStructReduce) : void
  // For now, we don't know how to go parallel in the absence of a combiner.
  if (!mtls->combFunc) {
    launchReduceSerial(ains, inLen, aout, mtls);
    return;
  }

  // Number of threads = "main thread" + number of other (worker) threads
  const uint32_t numThreads = mWorkers.mCount + 1;

  // In the absence of outconverter, we use the output allocation as
  // an accumulator, and therefore need to allocate one fewer accumulator.
  const uint32_t numAllocAccum = numThreads - (mtls->outFunc == nullptr);

  // If mDebugReduceSplitAccum, then we want each accumulator to start
  // on a page boundary.  (TODO: Would some unit smaller than a page
  // be sufficient to avoid false sharing?)
  if (mRSC->props.mDebugReduceSplitAccum) {
    // Round up accumulator size to an integral number of pages
    mtls->accumStride =
        (unsigned(mtls->accumSize) + unsigned(mPageSize)-1) &
        ~(unsigned(mPageSize)-1);
    // Each accumulator gets its own page.  Alternatively, if we just
    // wanted to make sure no two accumulators are on the same page,
    // we could instead do
    //   allocSize = mtls->accumStride * (numAllocation - 1) + mtls->accumSize
    const size_t allocSize = mtls->accumStride * numAllocAccum;
    mtls->accumAlloc = static_cast<uint8_t *>(memalign(mPageSize, allocSize));
  } else {
    mtls->accumStride = mtls->accumSize;
    mtls->accumAlloc = static_cast<uint8_t *>(malloc(mtls->accumStride * numAllocAccum));
  }

  const size_t accumPtrArrayBytes = sizeof(uint8_t *) * numThreads;
  mtls->accumPtr = static_cast<uint8_t **>(malloc(accumPtrArrayBytes));
  memset(mtls->accumPtr, 0, accumPtrArrayBytes);

  mtls->accumCount = 0;

  rsAssert(!mInKernel);
  mInKernel = true;
  REDUCE_ALOGV(mtls, 1, "launchReduceParallel(%p): %u x %u x %u, %u threads, accumAlloc = %p",
               mtls->accumFunc,
               mtls->redp.dim.x, mtls->redp.dim.y, mtls->redp.dim.z,
               numThreads, mtls->accumAlloc);
  if (mtls->redp.dim.z > 1) {
    mtls->mSliceSize = 1;
    launchThreads(walk_3d_reduce, mtls);
  } else if (mtls->redp.dim.y > 1) {
    mtls->mSliceSize = rsMax(1U, mtls->redp.dim.y / (numThreads * 4));
    launchThreads(walk_2d_reduce, mtls);
  } else {
    mtls->mSliceSize = rsMax(1U, mtls->redp.dim.x / (numThreads * 4));
    launchThreads(walk_1d_reduce, mtls);
  }
  mInKernel = false;

  // Combine accumulators and identify final accumulator
  uint8_t *finalAccumPtr = (mtls->outFunc ? nullptr : mtls->redp.outPtr[0]);
  //   Loop over accumulators, combining into finalAccumPtr.  If finalAccumPtr
  //   is null, then the first accumulator I find becomes finalAccumPtr.
  for (unsigned idx = 0; idx < mtls->accumCount; ++idx) {
    uint8_t *const thisAccumPtr = mtls->accumPtr[idx];
    if (finalAccumPtr) {
      if (finalAccumPtr != thisAccumPtr) {
        if (mtls->combFunc) {
          if (mtls->logReduce >= 3) {
            FormatBuf fmt;
            REDUCE_ALOGV(mtls, 3, "launchReduceParallel(%p): accumulating into%s",
                         mtls->accumFunc,
                         format_bytes(&fmt, finalAccumPtr, mtls->accumSize));
            REDUCE_ALOGV(mtls, 3, "launchReduceParallel(%p):    accumulator[%d]%s",
                         mtls->accumFunc, idx,
                         format_bytes(&fmt, thisAccumPtr, mtls->accumSize));
          }
          mtls->combFunc(finalAccumPtr, thisAccumPtr);
        } else {
          rsAssert(!"expected combiner");
        }
      }
    } else {
      finalAccumPtr = thisAccumPtr;
    }
  }
  rsAssert(finalAccumPtr != nullptr);
  if (mtls->logReduce >= 3) {
    FormatBuf fmt;
    REDUCE_ALOGV(mtls, 3, "launchReduceParallel(%p): final accumulator%s",
                 mtls->accumFunc, format_bytes(&fmt, finalAccumPtr, mtls->accumSize));
  }

  // Outconvert
  if (mtls->outFunc) {
    mtls->outFunc(mtls->redp.outPtr[0], finalAccumPtr);
    if (mtls->logReduce >= 3) {
      FormatBuf fmt;
      REDUCE_ALOGV(mtls, 3, "launchReduceParallel(%p): final outconverted result%s",
                   mtls->accumFunc,
                   format_bytes(&fmt, mtls->redp.outPtr[0], mtls->redp.outStride[0]));
    }
  }

  // Clean up
  free(mtls->accumPtr);
  free(mtls->accumAlloc);
