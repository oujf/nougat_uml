class Camera2Source
!!!34879799.java!!!	Camera2Source(inout context : MffContext, inout name : String)
        super(context, name);
        mOutputType = FrameType.image2D(FrameType.ELEMENT_RGBA8888, FrameType.WRITE_GPU);

        Context ctx = context.getApplicationContext();
        mCameraManager = (CameraManager) ctx.getSystemService(Context.CAMERA_SERVICE);

        mRS = RenderScript.create(context.getApplicationContext());
!!!34879927.java!!!	getSignature() : Signature
        return new Signature()
                .addOutputPort("timestamp", Signature.PORT_OPTIONAL, FrameType.single(long.class))
                .addOutputPort("video", Signature.PORT_REQUIRED, mOutputType)
                .addOutputPort("orientation", Signature.PORT_REQUIRED,
                        FrameType.single(float.class))
                .disallowOtherPorts();
!!!34880055.java!!!	onClose() : void
        Log.v(TAG, "onClose being called");
        try {
            mCamera.close();
            mSurface.release();
            mLooperThread.close();
        } catch (Exception e) {
            // TODO Auto-generated catch block
            e.printStackTrace();
        }
!!!34880183.java!!!	onOpen() : void
        mLooperThread = new CameraTestThread();
        Handler mHandler;
        try {
            mHandler = mLooperThread.start();
        } catch (Exception e) {
            // TODO Auto-generated catch block
            e.printStackTrace();
            throw new RuntimeException(e);
        }

        try {
            String backCameraId = "0";
            BlockingCameraManager blkManager = new BlockingCameraManager(mCameraManager);
            mCamera = blkManager.openCamera(backCameraId, /*listener*/null, mHandler);
        } catch (CameraAccessException e) {
            e.printStackTrace();
            throw new RuntimeException(e);
        } catch (BlockingOpenException e) {
            e.printStackTrace();
            throw new RuntimeException(e);
        }

        Element ele = Element.createPixel(mRS, Element.DataType.UNSIGNED_8,
                Element.DataKind.PIXEL_YUV);

        rgbConverter = ScriptIntrinsicYuvToRGB.create(mRS,ele);
        Type.Builder yuvBuilder = new Type.Builder(mRS,ele);

        yuvBuilder.setYuvFormat(ImageFormat.YUV_420_888);
        yuvBuilder.setX(mWidth);
        yuvBuilder.setY(mHeight);
        mAllocationIn = Allocation.createTyped(mRS, yuvBuilder.create(),
                Allocation.USAGE_SCRIPT | Allocation.USAGE_IO_INPUT);
        mSurface = mAllocationIn.getSurface();
        mAllocationIn.setOnBufferAvailableListener(this);
        rgbConverter.setInput(mAllocationIn);

        mBitmap = Bitmap.createBitmap(mWidth, mHeight, Bitmap.Config.ARGB_8888);
        mAllocationOut = Allocation.createFromBitmap(mRS, mBitmap);


        Log.v(TAG, "mcamera: " + mCamera);

        List<Surface> surfaces = new ArrayList<Surface>();
        surfaces.add(mSurface);
        CaptureRequest.Builder mCaptureRequest = null;
        try {
            BlockingSessionCallback blkSession = new BlockingSessionCallback();

            mCamera.createCaptureSession(surfaces, blkSession, mHandler);
            mCaptureRequest = mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
            mCaptureRequest.addTarget(mSurface);

            mCameraSession = blkSession.waitAndGetSession(SESSION_TIMEOUT_MS);

        } catch (CameraAccessException e) {
            e.printStackTrace();
            throw new RuntimeException(e);
        }

        try {
            mCameraSession.setRepeatingRequest(mCaptureRequest.build(), new MyCaptureCallback(),
                    mHandler);
        } catch (CameraAccessException e) {
            e.printStackTrace();
            throw new RuntimeException(e);
        }
        mProperties = null;
        try {
            mProperties = mCameraManager.getCameraCharacteristics(mCamera.getId());
        } catch (CameraAccessException e) {
            e.printStackTrace();
            throw new RuntimeException(e);
        }

!!!34880311.java!!!	onProcess() : void
        Log.v(TAG, "on Process");
        if (nextFrame()) {
            OutputPort outPort = getConnectedOutputPort("video");

            // Create a 2D frame that will hold the output
            int[] dims = new int[] {
                    mWidth, mHeight
            };
            FrameImage2D outputFrame = Frame.create(mOutputType, dims).asFrameImage2D();
            rgbConverter.forEach(mAllocationOut);
            mAllocationOut.copyTo(mBitmap);
            outputFrame.setBitmap(mBitmap);
            outPort.pushFrame(outputFrame);
            outputFrame.release();

            OutputPort orientationPort = getConnectedOutputPort("orientation");
            FrameValue orientationFrame = orientationPort.fetchAvailableFrame(null).asFrameValue();

            // FIXME: Hardcoded value because ORIENTATION returns null, Qualcomm
            // bug
            Integer orientation = mProperties.get(CameraCharacteristics.SENSOR_ORIENTATION);
            float temp;
            if (orientation != null) {
                temp = orientation.floatValue();
            } else {
                temp = 90.0f;
            }
            orientationFrame.setValue(temp);
            orientationPort.pushFrame(orientationFrame);
        }
!!!34880439.java!!!	nextFrame() : boolean
        boolean frameAvailable = mNewFrameAvailable;
        if (frameAvailable) {
            mNewFrameAvailable = false;
        } else {
            enterSleepState();
        }
        return frameAvailable;
!!!34880567.java!!!	onBufferAvailable(inout a : Allocation) : void
        Log.v(TAG, "on Buffer Available");
        a.ioReceive();
        synchronized (this) {
            mNewFrameAvailable = true;
        }
        wakeUp();
